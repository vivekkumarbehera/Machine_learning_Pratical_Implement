# -*- coding: utf-8 -*-
"""MachineLearningPraticalimplementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fISykwiMStSb4-PGvEafhyDjjZm_-fnN
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import load_diabetes
df=load_diabetes()
pd.DataFrame(df.data)

pd.DataFrame(df.target)

datset=pd.DataFrame(df.data)

datset.columns = df.feature_names

datset.head()

x=datset
y=df.target

y

#train test split
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)

x_train

#Standardizing the datstet
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

X_train=scaler.fit_transform(x_train)

X_train

X_test=scaler.transform(x_test)

X_test

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score

regressor=LinearRegression()
regressor.fit(X_train,y_train)

mse=cross_val_score(regressor,X_train,y_train,scoring='neg_mean_squared_error',cv=10)

np.mean(mse)

reg_pred=regressor.predict(x_test)

reg_pred

import seaborn as sns
sns.distplot(y_test-reg_pred)

#Ridge Reggression Problem
from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV

ridge_regressor=Ridge()

parameters={"alpha":[1,2,3,10,20,30,40,50,60,70,80]}
ridgecv=GridSearchCV(ridge_regressor,parameters,scoring='neg_mean_squared_error',cv=10)
ridgecv.fit(X_train,y_train)

print(ridgecv.best_params_)
print(ridgecv.best_score_)

ridge_pred=ridgecv.predict(x_test)

import seaborn as sns
sns.distplot(y_test-ridge_pred)

#LassoRegression
from sklearn.linear_model import  Lasso
lasso=Lasso()

parameters={"alpha":[1,2,3,10,20,30,50,60]}
lassocv=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=10)
lassocv.fit(X_train,y_train)

print(lassocv.best_params_)
print(lassocv.best_score_)